\chapter{Implementation and Results}
The following sub-chapters present the results of this master thesis. First, the requirements are summarized. Subsequently, the example computation of a Groth16 proof and verification is described in detail. The first artifact, the zero-knowledge decentralized application (\acrshort{zkdapp}), is demonstrated. The second artifact, an architecture proposal for the zero-knowledge data structure of spare part certification and metadata information, is introduced as an outcome of the \acrshort{zkdapp} evaluation.

\section{Summary of Requirements}
The requirements introduced in Chapter 2 and 3 are summarized as follows.

\begin{enumerate}
    \item Zero-knowledge proof systems are a disruptive technology in the domain of blockchain-based research and development. One project requirement is to \textbf{accumulate knowledge and current research outcomes} in this field to extend expertise within RAPADO \citep{ZedelJ}. The Groth16 algorithm is introduced in detail using an example calculation problem (Chapter 5.2). The problem is split and transformed into an arithmetic circuit in the step-wise computation, arriving at an \acrshort{r1cs}. From this, the \acrshort{qap} is calculated. Tools, e.g, homomorphic hiding and elliptic curve pairing, are also introduced. Ultimately, following the Groth16 protocol, the key and proof generation and verification mechanisms are illustrated.
    \item The requirement of \textbf{constructing a trade-off between privacy, confidentiality, and transparency} arises from preliminary work in the project and at the Department of Information Systems \citep{ZedelJ}. The use of blockchain-based solutions enables transparency at the cost of confidentiality. With the constantly increasing awareness for data privacy, combined with trust issues and regulatory data confidentiality requirements in the industry, zero-knowledge proof systems have to be explored and utilized to secure the adoption of project results and products in the future. The first minimum viable product (MVP) of the \acrshort{zkdapp} for \acrshort{mro} data attestations contributes to this goal and satisfies this requirement. The \acrshort{zkdapp} is organized as follows: the backend directory stores the JSON input schema, the solidity smart contracts, the circom circuit, and corresponding generated files. The lib directory stores shared files between the backend and frontend and hashing functions used, e.g., in the circuit code. The user interface (UI) directory finds the correct schema and stores a copy of the final protocol transcript key and the witness-generating file. It also stores the frontend code for the landing page and all corresponding pages to submit, attest to and verify \acrshort{mro} data.
    \item Current paper-based \acrshort{mro} documentation of aviation spare parts primarily sets the requirement for \textbf{fraud-preventive document authenticity checks, enabled through practical data formats and digitization of spare part documentation}. Fraud-preventive verification is covered via the \acrshort{zkdapp}. However, current data digitization efforts for spare part documentation need to be further addressed: the zero-knowledge data structure architecture enables consistent and temper-proof data storage via Merkle trees, and proofs specific memberships, e.g., mechanics who worked at a specific part at a given time, in zero-knowledge.
\end{enumerate}

\begin{comment}
-research disruptive technologies and creating knowledge in the project: calculation example Groth16
-privacy/confidentiality vs transparency : \acrshort{zkdapp}
-need for fraud-preventive verification mechanism enabled through effective data formats digitization of aviation parts and document data: architecture

Notizen:

In den Ausblick der \acrshort{zkdapp}
-für einen part die schwellenwerte finden
-time since last service
-validation network as attester—>Übergang zum 2.artefakt 

-schwellenwerte ausgelesen werden
-aber auch die attester müssen ausgelesen werden

—>release certificate: Behörde
—> shop report: MRO Betrieb

-MRO KPIs: für den Handel, aus den MRO Daten ergeben, aus Privatsphäre/Transparenz requirement, ohne dass man Einsicht ins gesamte shop report geben will
\end{comment}

\section{Groth16 Proof and Verification}
Let us use an example to illustrate the underlying mathematical methods applied in \acrshort{zksnark}s. The example calculation will use the knowledge of the coefficient assumption for simplification. In practice, the \acrshort{fft} is applied. First, the arithmetic circuit is transformed into an \acrshort{r1cs}. The \acrshort{r1cs} is used to obtain the \acrshort{qap}. Homomorphic hiding, elliptic curves, and pairing-based cryptography are introduced in more detail and put in context for the next steps of the calculation. Finally, the Groth16 protocol is introduced: First, the key generation steps are explained. Second, the proof is generated. Lastly, the verification steps are illustrated. Formal definitions are found in Chapter 4.2.

Say we want to prove we know a secret x so that

\[x^3 + x + 5 = 35\]

In this case, our secret is x = 3.
In practice, we would use hiding and modular arithmetic instead of real numbers and calculations since these are easy to forge and find solutions to, making the proof useless. For the \acrshort{r1cs} and \acrshort{qap}, we will proceed with real numbers to show the underlying mechanisms. The following will demonstrate how any computation that needs to be proven can be converted into polynomial format.

\subsubsection{Arriving at a R1CS}

A rank-1 constraint system is a mathematical format to help us reduce our problem into a less complex computational problem. First, we flatten the equation by writing a short program to break down the different steps to solve the equation.

\begin{enumerate}
    \item \(sum1 = x * x\)
    \item \(y = sum1 * x\)
    \item \(sum2 = y + x\)
    \item \(out = sum2 + 5\)
\end{enumerate}

As shown above, we arrive at an arithmetic circuit with 4 gates and the solution variables
\[x = 3, y = 27, sum1 = 9, sum2 = 30, out = 35.\]

From this, we can construct the solution vector \(s\), starting with a dummy variable of value 1, which we call \textit{one}.
Now, the solution vector \(s\) is
\begin{align}
    \Vec{s} &= \begin{pmatrix}
     one \\ x \\ out \\ sum1 \\ y \\ sum2
\end{pmatrix}
\end{align}
Each gate will be represented so that
\begin{align}
     \Vec{s}\cdot\Vec{a_i} * \Vec{s}\cdot\Vec{b_i} - \Vec{s}\cdot\Vec{c_i} = 0
\end{align}

Let us go through every gate and assign the values for \(a, b,\) and \(c\).
For the first gate \(sum1 = x*x\), the values of \(a, b,\) and \(c\) are assigned as follows:
\begin{align*}
    a_1 &=\begin{bmatrix}
        0 & 1 & 0 & 0 & 0 & 0
    \end{bmatrix}
\end{align*}
\begin{align*}
    b_1&=\begin{bmatrix}
        0 & 1 & 0 & 0 & 0 & 0 
    \end{bmatrix}
\end{align*}
\begin{align*}
    c_1&=\begin{bmatrix}
        0 & 0 & 0 & 1 & 0 & 0
    \end{bmatrix}
\end{align*}

The above is correct because the dot product of s and a, multiplied by the dot product of \(a\) and \(b\), subtracted by the dot product of \(s\) and \(c\), is 0.

This procedure is applied to every gate. Let us show more complex gates to underline the calculation. For example, the third gate and the fourth gate. The third gate \(sum2=y+x\) could be approached as the first gate by setting the variables in the equation to 1. However, this would not fulfill the equation shown in (5.2). Therefore, the correct values for \(a_3, b_3 \text{ and }c_3\) are
\begin{align*}
    a_3 &=\begin{bmatrix}
        0 & 1 & 0 & 0 & 0 & 0
    \end{bmatrix}
\end{align*}
\begin{align*}
    b_3&=\begin{bmatrix}
        1 & 0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
\end{align*}
\begin{align*}
    c_3&=\begin{bmatrix}
        0 & 0 & 0 & 0 & 0 & 1
    \end{bmatrix}
\end{align*}

Here, we make use of the dummy vector \textit{one} so that we can arrive at 
\[30 * 1 - 30 = 0.\]

The fourth gate \(out=sum2+5\) must also be approached by holding to the dot product equation in (5.2). We have to make use of the dummy vector once again. Setting the values of \(one, sum2 \text{ and } out\)  to 1 will give us the following incorrect solution:
\begin{align*}
     \Vec{s}\cdot\Vec{a_4} * \Vec{s}\cdot\Vec{b_4} - \Vec{s}\cdot\Vec{c_4} \neq 0.
\end{align*}
The calculation shows \(30 * 1 - 35 \neq 0\), which means we need to add 5 so that the dot product of vector \(s \text{ and } a\) adds up to 35. Therefore, the values of \(a_4, b_4 \text{ and }c_4\) are as follows:
\begin{align*}
    a &=\begin{bmatrix}
        5 & 0 & 0 & 0 & 0 & 1
    \end{bmatrix}
\end{align*}
\begin{align*}
    b&=\begin{bmatrix}
        1 & 0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
\end{align*}
\begin{align*}
    c&=\begin{bmatrix}
        0 & 0 & 1 & 0 & 0 & 0
    \end{bmatrix}
\end{align*}

By combining our results into matrices, we can set up the corresponding \acrshort{r1cs}:

\begin{align}
A&=\begin{pmatrix}
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 1 & 0 & 0 & 1 & 0 \\
    5 & 0 & 0 & 0 & 0 & 1
\end{pmatrix}
\end{align}
\begin{align*}
B&=\begin{pmatrix}
    0 & 1 & 0 & 0 & 0 & 0 \\
    0 & 1 & 0 & 0 & 0 & 0 \\
    1 & 1 & 0 & 0 & 0 & 0 \\
    1 & 0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{align*}
\begin{align*}
C&=\begin{pmatrix}
    0 & 0 & 0 & 1 & 0 & 0 \\
    0 & 0 & 0 & 0 & 1 & 0 \\
    0 & 0 & 0 & 0 & 0 & 0 \\
    0 & 0 & 1 & 0 & 0 & 0
\end{pmatrix}
\end{align*}

\subsubsection{From \acrshort{r1cs} to \acrshort{qap}}

The \acrshort{r1cs} shows three matrices \(A, B \text{ and }C\) representing the four gates of length six. It is transformed into a \acrshort{qap} by expressing polynomials as sums of Lagrange Interpolation (Chapter 4.2.1). This results in three sets of polynomials \(A_i(X), B_i(X) \text{ and }C_i(X)\), each consisting of six polynomials of degree three. In the following, we will summarize the reason for setting up a \acrshort{qap} instead of continuing with the \acrshort{r1cs}. Lagrange Interpolation allows us to develop polynomial coefficients representing each gate when evaluated at an \(X\) in the range of the number of constraints (gates). With \(X = 1\), the Lagrange Interpolation can be explained quite well because it means that we can add up the coefficients of the polynomials in \(A_i(X), B_i(X) \text{ and }C_i(X)\). Each set of polynomials is built so that evaluated at gate \(X\), whereby \(X\) has to be in the range of the number of gates (constraints), will deliver the specific value of \(X\) and 0 for the other values in that specific range.\newline
The \acrshort{qap} for our example:
\begin{align*}
    A_i(X) \\
    \begin{bmatrix}
        -5.0 & 9.166 & -5.0 & 0.833 \\
        8.0 & -11.33 & 5.0 & -0.666 \\
        0.0 & 0.0 & 0.0 & 0.0 \\
        -6.0 & 0.5 & -4.0 & 0.5 \\
        4.0 & -7.0 & 3.5 & -0.5 \\
        -1.0 & 1.833 & -1.0 & 0.166
    \end{bmatrix} \\
\end{align*}
\begin{align*}
        B_i(X) \\
    \begin{bmatrix}
        3.0 & -5.166 & 2.5 & -0.333 \\
        -2.0 & 5.166 & -2.5 & 0.333 \\
        0.0 & 0.0 & 0.0 & 0.0 \\
        0.0 & 0.0 & 0.0 & 0.0 \\
        0.0 & 0.0 & 0.0 & 0.0 \\
        0.0 & 0.0 & 0.0 & 0.0
    \end{bmatrix}
\end{align*}
\begin{align*}
        C_i(X) \\
    \begin{bmatrix}
        0.0 & 0.0 & 0.0 & 0.0 \\
        0.0 & 0.0 & 0.0 & 0.0 \\
        -1.0 & 1.833 & -1.0 & 0.166 \\
        4.0 & -4.833 & 1.5 & -0.166 \\
        -6.0 & 9.5 & -4.0 & 0.5 \\
        4.0 & -7.0 & 3.5 & -0.5
    \end{bmatrix}
\end{align*}
The corresponding values in the matrices represent polynomial coefficients and shall be read from right to left, e.g., \(A1(X) = 0.833x^3 - 5x^2 + 9.166x -5\). For example:
\begin{align}
     X = 1 \\
    A1(1) = 0, A2(1) = 1, A3(1) = 0, A4(1) = 0, A5(1) = 0, A6(1) = 0
\end{align}
Comparing the results with the first vector \(a\) of the first gate, we see that the results represent the first gate.
For example, evaluating \(A, B \text{ and }C\) at \(X = 1\) means adding up the coefficients of the first polynomial of \(A\), which will result in a value matching to the vector value in the first gate. Then, the next polynomial in A, etc. It will result in a vector of length six and be correct if the values match vector a from the first gate in our \acrshort{r1cs}. The same is done by evaluating the polynomials with \(X\), whereby \(X\) starts at \(1\) and ends at the number of gates, in our case \(X=\{1,2,3,4\}\).
However, it would be cumbersome to evaluate each constraint individually. This is why we can make use of the \acrshort{qap} to check whether the dot product equation of the polynomials will hold:
\begin{align}
    A_i(X)\cdot \Vec{s} * B_i(X)\cdot \Vec{s} - C_i(X)\cdot \Vec{s} = H(X) * Z(X)
\end{align}
Interestingly, the left side of the equation is our target polynomial \(T(X)\), which we want to prove.
Now, look at the equation's right side in (5.6). \(Z(X)\) is known if we know the number of constraints. In Groth16, it is made available in the trusted setup. In this case, we have four gates, so we arrive at
\begin{align}
    Z(X) = (x-1)(x-2)(x-3)(x-4)
\end{align}
\(H(X)\) is the hiding of our initial minimal example, those inputs we do not want to share but prove we know the solution. What role hiding plays will be explained shortly. We want to finish looking at the equation in (5.6). In essence, we want to prove that we know a polynomial and its solution so that
\begin{align}
    T(X) / Z(X) = H(X)
\end{align}
In our example, \(H(X)\) is also a polynomial. The \acrshort{qap} is correct if \(H(X)\) is a polynomial without remainder. In this example, the resulting
\[H(X) = -0.44x^3 + 17.055x^2 - 3.666x.\]

Practically, the coefficients of each polynomial in \(A_i(X), B_i(X) \text{ and }C_i(X)\) are publicly known. The same can be said for \(Z(X)\) through knowing the number of constraints (in this example, we have four constraints). The prover can calculate the coefficients of \(H(X)\) by dividing T(X) / \(Z(X)\). However, there is no zero-knowledge yet, since the prover has to prove knowledge of vector \(s\) and \(H(X)\) without revealing it.
\newpage

\subsubsection{Hiding}
\acrshort{zksnark}s are dependent on a trusted setup releasing these parameters. The goal is to prove knowledge of the polynomial \(H(X)\) with all its coefficients without disclosing this information. Therefore, the trusted setup also provides a random secret point \(P\). Note that \(P\) is hashed, calculated once, and deleted from memory. Depending on the number of constraints, a certain amount of \(P\) values are needed. In our example, we have four constraints, which need \(P = {1, P, P^2, P^3}\), whereby the value of \(P^3\) corresponds to the value of \(x^3\) when the polynomials are evaluated. The following values of \(P\) are provided

\begin{align}
    hh(1), hh(P), hh(P^2), ..., hh(P^\textsuperscript{(no. of constraints - 1)})
\end{align}

The trusted setup makes these values publicly available in the CRS.

With our previous knowledge, we know that the proof will consist of
\begin{align}
    \frac{hh[A(P)] * hh[B(P)] - hh[C(P)])}{hh[Z(P)]} = hh[H(P)]
\end{align}

The hidings of our polynomials are numbers that currently can just be forged. The following will show how it can be proven that these numbers are hidings of the polynomials \(A(X)\), \(B(X)\) and \(C(X)\) in \(P\) which is not known to anybody. Furthermore, we need to prove that in order to arrive at \(A(X)\), \(B(X)\), and \(C(X)\), the same solution vector \(s\) was used (5.6). 

In order to approach the first problem, proving that the hidings of \(A(X)\),  \(B(X)\) and \(C(X)\) were calculated in \(P\), we need to "extend" \(P\) by the same number, namely \(u\). The \acrshort{crs} also consists of \(hh(u*P), hh(u*P^2), hh(u*P^3)\), i.e., it consists of two sets of hidings. We know that \(A(X)\) is a linear combination of the values of vector s inserted into the polynomials A1, A2, A3, etc. of A. B calculating \(hh[A(P)]\) and \(hh[A(u*P)]\) and looking if \(hh[A(P)] = u * hh[A(u*P]\) holds, shows that the hiding of \(A(X)\) calculated in \(P\) is indeed a result of the linear combination of A1, A2, A3, etc. and the values of the vector s (5.6). All we did was prove that the same sets of hidings of \(P\) were used to arrive at these numbers. The same is applied to the hidings of \(B(X)\), \(C(X)\) in P.

For the second problem, to prove the same values of vector s were used to arrive at the hidings of \(A(X)\), \(B(X)\) and C(X) in \(P\) a similar approach can be used. In our example, vector s has six solution variables. We use a new variable, K as
\begin{align}
    K = K1 + K2 + K3 + K4 + K5 + K6
\end{align}
\begin{align*}
    K1 = A1(P) + B1(P) + C1(P)\\K2 = A2(P) + B2(P) + C2(P)
\end{align*}
\begin{center}
    ... \\
\end{center}
\begin{align*}
    K6 = A6(P) + B6(P) + C6(P)
\end{align*}
By checking that 
\begin{align}
    hh[K(P)] = one*hh[K1] + x * hh[K2] + out * hh[K3] + ... + sum2 * hh[K6],
\end{align}
we can prove that the same coefficients of vector s were used. It is nearly impossible to come up with numbers that hold for another \(P\) and to create proofs with the knowledge of the coefficients.

\subsubsection{Homomorphic Hiding}

\(y = hh(x)\) is a hashing function. It is collision-resistant, i.e., one cannot guess anything of \(x\) from \(y \). For zero-knowledge proofs, more than this property is required. The hashing function should also preserve algebraic structures so the checks in, e.g., (5.10), can be performed. Let us divide the term Homomorphic Hiding into two sections to explain in more detail.
A function \(y = hh(x) = e^x\) is homomorphic if
\begin{align}
    hh(a*x1 + b*x2) = e^\textsuperscript{a*x1+b*x2} = e^\textsuperscript{a*x1} * e^\textsuperscript{b*x2} = hh(x1)^a * hh(x2)^b
\end{align}
As seen in (5.13), the basic exponential laws hold. However, this function is not hiding because one could calculate the logarithmic base \(e\) of \(x\) because of working with only real numbers \begin{math}\mathbb{R}  
\end{math} so far.

We must express variables in a finite field as modulo \(p\), with \(p\) being a large prime. The finite field consists only of integer inputs in the range of 1 and some value \(p-2\). This way, expressing values in modular arithmetic, nobody can guess or calculate our base \(e\) anymore. Now,
\begin{align}
    y = hh(x) = G^x,
\end{align}
where \begin{math}\mathbb{G}\end{math} is a value in the finite field \begin{math}\mathbb{F}_p\end{math} and \(y\) will always be expressed as modulo \(p\).

With homomorphic hiding being introduced, we know all the tools to prove that we can calculate the equation in (5.8) with the polynomials from the \acrshort{qap} and the same values of vector \(s\) without knowing any \(P\) and \(u * P\). We know how the proof is calculated without revealing our solution vector \(s\). The following deals with verifying that the above equations hold without revealing the solution vector \(s\).

\subsubsection{Elliptic Curve Pairing}
The goal of \acrshort{pcp} and pairing-based zero-knowledge algorithms is to create a succinct proof that a defined computation with given inputs produces specifically known outputs without revealing any information about them and to show that the constraints of that computation hold. Eventually, we want to check if the following equality holds, i.e., that after transforming our problem into a polynomial structure, we know some polynomials so that

\begin{align}
    \frac{A(x) * B(x)}{Z(x)} = H(x) + C(x)
\end{align}

We have the polynomials \(A, B \text{ and }C\), not expressed in real numbers but mapped to a finite field with a large prime number. We can calculate \(H(X)\) as in (5.8). Now, we will use generators for each of our polynomials to produce points on an elliptic curve. This is necessary to use pairing, which allows us to check if equations, e.g., (5.13), hold without knowing the actual variable values in these equations. In the following, some preliminaries will be introduced to create a basis for the Groth16 \acrshort{crs} generation, proofing, and verification mechanism.

Elliptic curves define collision-resistant one-way functions, i.e., homomorphic hiding functions. An elliptic curve is a polynomial, e.g., the elliptic curve used in Bitcoin (Figure \ref{fig:test1}). 

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{Pictures/bitcoinec.png}
  \caption{\(y^2 = x^3 +7\)}
  \label{fig:test1}
\end{minipage}%
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=.7\linewidth]{Pictures/y2x3.png}
  \caption{\(y^2 = x^3\)}
  \label{fig:test2}
\end{minipage}
\end{figure}

Elliptic curves are useful for \acrshort{zksnark}s because of the discrete logarithm problem, which is believed to be very hard to solve. Given a point \(g\) on the elliptic curve and a multiple of that point, \(n*g\), it is impossible to solve n, even if \(g\) and \(n*g\) are given. In order to choose an elliptic curve that offers homomorphic hiding, we need to implement a mapping between our known numbers of the finite field \begin{math}\mathbb{F}_p\end{math} and a set of points on the elliptic curve (hidden space). Let \begin{math}\mathbb{F}_p\end{math} be a finite field of order \(p\), whereby \(p\) is a large prime, e.g., if \(p=97\), then \begin{math}\mathbb{F}_p\end{math} \(=\{0, 1, 2, 3, ..., 96\}\) For this, we are going to take a generator point \(g = (x1,y1)\) that lies on the elliptic curve and multiply it with every element \({element}_i\) in \begin{math}\mathbb{F}_p\end{math}. For example, \(g + g = 2*g\) is calculated by putting a tangent line on \(g\), and wherever the line crosses the elliptic curve, we receive the result by using the opposite signs of that point. To arrive at \(2*g + g = 3*g\), the point \(2*g\) is used to draw a line to \(g\), see where the line further intersects with the elliptic curve, and use the opposite signs of that point to arrive at \(3*g\). This is repeated for every \(element\) in \begin{math}\mathbb{F}_p\end{math}. As a result, we have our finite field mapped to a hidden space on the elliptic curve. In summary, every 
\(element\) is hidden by
\begin{align}
    hh(element) = element * g
\end{align}
Additionally, we have to define what 0 and 1 are. The element 0 results from subtracting a point on the elliptic curve, i.e., when point \(g\) goes to infinite. 1 is the point \(g\) itself.
Now, we have achieved homomorphic addition:
\begin{align}
    (A + B) \longrightarrow (A + B) * g = A*g + B*g
\end{align}

In order to use elliptic curve pairing to verify \acrshort{zksnark}s proofs, e.g., Groth16, we need to achieve a limited homomorphic multiplication operator. The hidden space is a group of points generated by the finite field elements and the generation point, \(g1\), on the elliptic curve. Now, we want to choose a subgroup \begin{math} \mathbb{G}_1\end{math} from that group. We choose that subgroup so that the number of elements we chose, \(r\), is a prime number too. Having found \(r\), we can continue to choose the embedding degree of the elliptic curve. In Groth16, the proving key and verification key consist of \begin{math} \mathbb{G}_1\end{math} and \begin{math} \mathbb{G}_2\end{math} element. The embedding degree \(k\) has to be found so that \(p^k-1\ |\ r\), i.e., is a multiple of it. Let us use a minimal example to show how to arrive at \begin{math} \mathbb{G}_1\end{math} and \begin{math} \mathbb{G}_2\end{math}.
Let us define an example base field \begin{math}\mathbb{F}_p\end{math} \(= \{0,1,2\}\) with \(p = 3\). We have found an embedding degree \(k=2\). In order to achieve our goal of creating a subgroup \begin{math} \mathbb{G}_2\end{math}, we need to extend our base field by a defining polynomial. This polynomial is of degree \(k\), and no element of our base field evaluates it to 0. In summary, we have the following:

\begin{align}
    \mathbb{F}_p = \{0,1,2\}, p = 3, k = 2
\end{align}

Defining polynomial for field extension \begin{math}\mathbb{F}_p^k\end{math}: 
\begin{align*}
    f(x) = z^2 +1 \\
    f(0) = 1\\
    f(1) = 2\\
    f(2) = 5 mod 3 = 2
\end{align*}

As shown in (5.18), none of the base field elements make f(x) evaluate to 0. In order to create the elements of the field extension \begin{math}\mathbb{F}_p^k\end{math}, we have to create all possible degree 2 polynomials out of the combinations of our base field \begin{math}\mathbb{F}_p\end{math}. For example, one possible polynomial with the coefficients from our base field is:

\begin{align}
    1*z^2+2*z+0 
\end{align}   
\begin{align*}
    (z^2+2*z)\mod (z^2+1) = 2*z-1\mod 3 = 2*z+2
\end{align*}
\(2*z+2\) is one element of the extension field \begin{math}\mathbb{F}_p^k\end{math}. In total, \begin{math}\mathbb{F}_p^k\end{math} has 9 elements, all calculated as in (5.18). In Summary, the elements of our extension field \begin{math}\mathbb{F}_p^k\end{math} are
\begin{align}
\{0, 1, 2, z, z+1, z+2, 2z, 2z+1, 2z+2\}
\end{align}

As shown in (5.20), the elements of the extension field are polynomials of degree up to \(k-1\). Addition and multiplication are defined in the way that coefficients are calculated \(\mod 3\) and polynomials \(\mod z^2+1\), the defining polynomial  
\(f(x)\) from (5.18).

Now, having our extension field, we can use it to create \begin{math}\mathbb{G}_2\end{math}, a subgroup of points of the same elliptic curve used for \begin{math}\mathbb{G}_1\end{math}, but with elements of \begin{math}\mathbb{F}_p^k\end{math}, instead of base field \begin{math}\mathbb{F}_p\end{math}. For this, we have to define points, whereby x and y coordinates are polynomials from \begin{math}\mathbb{F}_p^k\end{math}. \begin{math}\mathbb{G}_2\end{math} will consist of combinations from \begin{math}\mathbb{F}_p^k\end{math} in the form of \((x,y)\), which satisfy the elliptic curve. 

Pairings are bilinear maps that combine elements of two spaces to receive an element of a third space, e.g., matrix multiplication. In Groth16, the following pairing notation is used:

\begin{align}
    e: \mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_T
\end{align}

The result of all steps performed previously is an incomplete homomorphic multiplication that enables us to check that the correct polynomial coefficients were used for \(A(x), B(X), \text{ and }C(x)\), as well as the same solution vector \(s\). It is incomplete because not more than two elements can be multiplied. However, this satisfies the use case for \acrshort{zksnark}s. 

\subsubsection{Groth16}

Preliminaries to understand the Groth16 protocol have been covered. In the following, we will describe the setup, proof, and verification steps in Groth16. The parameters are summarized in Table \ref{tab:Groth16Params}.

\setlength{\tabcolsep}{2ex}
\renewcommand{\arraystretch}{1.5}%
\begin{table}[hbt]
	\centering
	    \caption{Groth16 - Parameter Summary}
		\begin{tabular}{| m{0.3\linewidth} | m{0.6\linewidth} |}
		\hline
		\textbf{Parameter} & \textbf{Definition}\\ \hline
            \(n,m\) & number of constraints, number of variables\\ \hline
            \begin{math}\mathbb{F}_p\end{math} & finite field of prime order p\\ \hline 
            \begin{math}\mathbb{G}_1, \mathbb{G}_2, \mathbb{G}_T\end{math} & groups of points of prime order p satisfying an elliptic curve\\ \hline
            \begin{math}\mathbb{G}_1 \times \mathbb{G}_2 \to \mathbb{G}_T\end{math}& bilinear pairing \\ \hline
            \begin{math}g_T = e(g_1, g_2)\end{math}& generators with mapping \\\hline
            \begin{math}\bigl\{A_i(X), B_i(X), C_i(X)\bigl\}_{i=0}^m\end{math} & encoded computation as result of \acrshort{r1cs} and \acrshort{qap}: three sets of polynomials of degree \(n-1\)\\ \hline
            \(Z(x) = (x-1)*(x-2) * \newline (x-3)...(x-(n-1))\) &  minimal polynomial, known because n is known \\ \hline
            \(l\) & number of public inputs \\ \hline
            \((s_1,...,s_l)\) & elements of witness whose inputs are public \newline (e.g., out = 35 in our example) \\ \hline
            \((s_{l+1},s_{l+2},...s_m)\) & elements of witness for secret input x, with \(s_0 = 1\) \\ \hline
	\end{tabular}
\label{tab:Groth16Params}
\end{table}

\subsubsection{Key generation}

The proving and verification keys are obtained from the Common Reference String (\acrshort{crs}) via multi-party computation. From \begin{math}\mathbb{F}_p\end{math}, a set of random values is generated. This toxic waste (tw), or trapdoor, must be secret and forgotten from memory because knowledge of it enables forged proofs. Note that \begin{math}\tau\end{math} is the random point \(P\) from our examples. From the toxic waste, polynomial \(L_i(x)\) is defined:
\begin{align}
    tw = (\alpha, \beta, \gamma, \delta, \tau) 
\end{align}
\begin{align*}
    L_i(x) = \beta * A_i(X) + \alpha * B_i(X) + C_i(X)
\end{align*}
The \acrshort{crs} consist of \begin{math} \sigma = ([\sigma_1]_1,[\sigma_2]_2)\end{math}, which are elements of \begin{math} \mathbb{G}_1, \mathbb{G}_2\end{math}.

\begin{align}
    [\sigma_1]_1 = 
    &\ [(\alpha, \beta, \gamma, \delta, \\
    &\ 1, \tau, \tau^2, \tau^3, ..., \tau^{n-1}, \\
    &\ \frac{L_0(\tau)}{\gamma}, ..., \frac{L_l(\tau)}{\gamma}, \\
    &\ \frac{L_{l+1}(\tau)}{\delta}, ..., \frac{L_m(\tau)}{\delta})]_1 
\end{align}
\begin{align*}
    [\sigma_2]_2 = [(\beta, \gamma, \delta, \ 1, \tau, \tau^2, \tau^3, ..., \tau^{n-1})]_2
\end{align*}

\begin{itemize}
    \item (5.23): elements of the toxic waste
    \item (5.24): powers of \begin{math}\tau\end{math} of degree up to \(n-1\)
    \item (5.25): The polynomial is chosen from the set of polynomials of \(A(X), B(X), C(X)\), which corresponds to the place of the public input of the solution vector. In our starting example, \(out = 35\) is the public input (since this is our only public input, \(l=1\)). The public input is in third place in s. Hence, \(A_3(X), B_3(X), C_3(X)\) are chosen, evaluated at \begin{math}\tau\end{math} and multiplied by \begin{math} \alpha, \beta\end{math}.
    \item (5.26): Same as (5.25), but for the non-public inputs of \(s\). All elements of \begin{math} [\sigma_1]_1 \end{math} are \begin{math}\mathbb{G}_1\end{math} elements, e.g., \begin{math}\alpha_1 = g_1 * \alpha\end{math}.
\end{itemize}

The proving key consists of the following elements:
\begin{itemize}
    \item \([(\alpha, \beta, 1, \tau, \tau^2, \tau^3, ..., \tau^{n-1}, \frac{L_{l+1}(\tau)}{\delta}, ..., \frac{L_m(\tau)}{\delta})]_1\)
    \item \([(1, \gamma, \delta)]_2\)
    \item circuit information about the polynomials:
    
    \(A_0(X), A_1(X), ..., A_m(X)\)
    
    \(B_0(X), B_1(X), ..., B_m(X)\)
    
    \(C_0(X), C_1(X), ..., C_m(X)\)
    
    \(Z(x) = (x-1)(x-2)(x-3)...(x-(n-1))\)
\end{itemize}

The verification key consists of the following elements:
\begin{itemize}
    \item \([(1, \frac{L_0(\tau)}{\gamma}, ..., \frac{L_l(\tau)}{\gamma})]_1\)
    \item \([(1, \gamma, \delta)]_2\)
    \item precomputed pairing \([\alpha * \beta]_T\), which is a \begin{math}\mathbb{G}_T\end{math} element
\end{itemize}

\subsubsection{Generating the proof}

Two random numbers \(r, t\) are generated from \begin{math}\mathbb{F}_p\end{math}, that are used to compute

\begin{enumerate}
    \item \begin{math} A= \alpha + s_0*A_0(\tau) + s_1*A_1(\tau) + ... + s_m*A_m(\tau) + r\delta\end{math}
    \item \begin{math} B= \beta + s_0*B_0(\tau) + s_1*B_1(\tau) + ... + s_m*B_m(\tau) + t\delta\end{math}
    \item \begin{math} C= \frac{s_{l+1}L_{l+1}(\tau)}{\delta} + \frac{s_{l+2}L_{l+2}(\tau)} + ... +\frac{s_{lm}L_{lm}(\tau)}{\delta} + \frac{H(\tau)Z(\tau)}{\delta} + At + Br - rt\delta\end{math}
\end{enumerate}

The proof \begin{math}\pi\end{math} consists of two elements from \begin{math}\mathbb{G}_1\end{math} and one element from \begin{math}\mathbb{G}_2\end{math}:
\begin{align}
    \pi = ([A]_1, [B]_2, [C]_1)
\end{align}

\subsubsection{Verification}

In Groth16, three pairings are checked during verification. \begin{math}[\alpha * \beta]_T\end{math} is a precomputed pairing and is made available in the setup phase. The verification computation receives proof \begin{math} \pi\end{math} and accepts it only if the following equation holds:
\begin{align}
    [A]_1 * [B]_2 = [\alpha]_1[\beta]_2 + \bigl[\frac{s_0L_0(\tau)}{\gamma}+ \frac{s_1L_1(\tau)}{\gamma} + ... + \frac{s_lL_l(\tau)}{\gamma}\bigr]_1 * [\gamma]_2 + [C]_1 * [\delta]_2
\end{align}

As shown in (5.28), the following three pairings are needed to be checked:

\begin{itemize}
    \item \(e([A]_1, [B]_2)\)
    \item \begin{math}
        e(\bigl[\frac{s_0L_0(\tau)}{\gamma}+ \frac{s_1L_1(\tau)}{\gamma} + ... + \frac{s_lL_l(\tau)}{\gamma}\bigr]_1 , [\gamma]_2)
    \end{math}
    \item \begin{math}
        e([C]_1, [\delta]_2)
    \end{math}
\end{itemize}

Let us evaluate the verification equation in (5.28). The left-hand side evaluates as follows:

\begin{equation*}
\begin{split}
    [A]_1 * [B]_2 = [A*B]_T &= [\alpha + s_0*A_0(\tau) + s_1*A_1(\tau) + ... + s_m*A_m(\tau) + r\delta]_1 \ *\\
    &\ \ \ \ [\beta + s_0*B_0(\tau) + s_1*B_1(\tau) + ... + s_m*B_m(\tau) + t\delta]_2 \\
    &= [(\alpha + A(\tau) + r\delta) * (\beta + B(\tau) + t\delta)]_T\\
    &= [\alpha * \beta]_T + [\alpha * B(\tau)]_T + [\alpha * t\delta]_T \ + [A(\tau) * \beta]_T \ + \\
    &\ \ \ \ [A(\tau) * B(\tau)]_T + [A(\tau) * t\delta]_T + [r\delta * \beta]_T + [r\delta * B(\tau)]_T +\\
    &\ \ \ \ [r\delta * t\delta]_T \\
    \\
    &= [A(\tau) * B(\tau)]_T \textcolor{blue}{\ +\ [\alpha * \beta]_T + [\alpha * B(\tau)]_T + [\alpha * t\delta]_T} \\
    &\ \ \textcolor{blue}{+ [A(\tau) * \beta]_T \ + [A(\tau) * t\delta]_T + [r\delta * \beta]_T + [r\delta * B(\tau)]_T} \\
    &\ \ \textcolor{blue}{+ [r\delta * t\delta]_T}
\end{split}
\end{equation*}

The right-hand side evaluates to:
 \begin{equation*}
     \begin{split}
    &=[\alpha]_1[\beta]_2 + \bigl[\frac{s_0L_0(\tau)}{\gamma}+ \frac{s_1L_1(\tau)}{\gamma} + ... + \frac{s_lL_l(\tau)}{\gamma}\bigr]_1 * [\gamma]_2 + [C]_1 * [\delta]_2 \\
    &=[\alpha * \beta]_T + [(s_0L_0(\tau) + s_1L_1(\tau) + ... + s_lL_l(\tau))]_T + [(s_{l+1}L_{l+1}(\tau) + s_{l+2}L_{l+2}(\tau) + ... \\
    &\ \ \ + s_{lm}L_{lm}(\tau)) + H(\tau)Z(\tau) + At\delta + Br\delta - rt\delta\delta]_T
     \end{split}
 \end{equation*}

Now, we can replace A and B. We also see that the middle of the equation is \(L_i(\tau)\).
 \begin{equation*}
     \begin{split}
     &=[H(\tau) * Z(\tau) + C(\tau)]_T \textcolor{blue}{\ +\  [\alpha * \beta]_T + [\alpha * B(\tau)]_T + [\alpha * t\delta]_T + [A(\tau) * \beta]_T} \\
     &\ \ \ \textcolor{blue}{+ [A(\tau) * t\delta]_T + [r\delta * \beta]_T + [r\delta * B(\tau)]_T + [r\delta * t\delta]_T}
     \end{split}
 \end{equation*}

Eventually, we got the equality check we wanted to achieve (5.15). The use of the secret encoded values \(\alpha, \beta\) of the toxic waste (5.22) forces the prover algorithm to use the same coefficients of the solution vector (witness) to compute \(A(X), B(X), C(X)\). \(\gamma, \delta\) ensure that the public inputs of order \(l\) are independent from the solution vector (witness). In order to achieve the zero-knowledge aspect, \(r, s\) are used to shift the proof randomly.

\section{PLONK-based zk-DApp}
The decentralized application for zero-knowledge \acrshort{mro} data attestation (\acrshort{zkdapp}) facilitates data entries and data sharing between \acrshort{mro} data owners (submitters) and aviation authorities (attesters) in zero-knowledge. This software artifact attempts to ensure compatibility between the lack of trust among industry participants and the need for data verification and transparency (a trade-off between requirements within the project). \acrshort{mro} data need to be transparent for potential secondary market trading of aviation spare parts without giving full access to the documentation, e.g., to the entire shop report.

\subsection{Implementation}
The zero-knowledge part of the \acrshort{zkdapp} is implemented via circom and snarkjs, developed by iden3. iden3 is an open-source project focused on scalable and distributed identity systems on zero-knowledge proofs, i.e., providing protocols, data structures, and modules. The current objectives include achieving self-sovereign identities free of charge, minimizing on-chain transactions, re-designing privacy with non-reusable proofs, creating complete products, e.g., user wallets, and focusing on community standardization \citep{iden3aboutus}. Circom is Rust-based and allows one to write and compile arithmetic circuits. In circom, there is a data type called field elements, which per default represents values modulo a large prime number based on the BN128 elliptic curve \citep{circom}. \acrshort{r1cs} files are generated by compiling the circuit: the constraint system in binary format, a symbols file for debugging, and files that are necessary to generate the witness. In order to compute the witness, an input file in JSON format needs to be specified that contains the witness information. 

In the \acrshort{zkdapp}, the submitter enters the information to be verified, which is processed according to an input schema. The witness is computed and saved in a file format accepted by snarkjs. Snarkjs is a JavaScript library that continues with the outputs from circom and executes a specified zero-knowledge proof protocol, e.g., currently, Groth16, \acrshort{plonk}, and Fflonk are supported \citep{snarkjsdoc}. For this use case, snarkjs' \acrshort{plonk} implementation is utilized. For the verification and intermediate result hashes, a powers of tau file is utilized to perform the multi-party computation. In Groth16, it is utilized during the trusted setup (5.2.1). In \acrshort{plonk}, this is the source of public randomness (5.2.2). Figure \ref{fig:zk-DAppgeneral} shows the main steps performed for a \acrshort{plonk}-based \acrshort{zkdapp}. \acrshort{plonk} does not require a trusted ceremony for each circuit, i.e., the powers of tau ceremony is universal. After compiling the circuit and calculating the witness, the snarkjs \acrshort{plonk} can be set up. A final protocol transcript key (zkey) is generated and verified. The zero-knowledge key includes proving and verification key \citep{snarkjsdoc}. From the zkey, the verification key is exported in JSON format. With this verification key file, the final zkey file and the witness file, the proof file, and the file with the public inputs and outputs are generated. These two files and the verification key are used to verify the proof. The verifier is transformed into a smart contract (PlonkVerifier.sol) that performs the verification. In order to utilize the PlonkVerifier smart contract exported in the previous step, an interface must be created (IPlonkVerifier.sol), which initiates verifyProof and outputs a true or false. The ZkDocument.sol smart contract, which stores user inputs, e.g., the commitments and trusted attesters, uses this interface to verify the proof and update the states of the smart contracts. With every user input, a witness and proof are calculated. The commitment is posted, and the smart contracts are updated. Once verified, the user interface (UI) shows an update, e.g., a green highlighting. 
\begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{Pictures/circom snarkjs process flow.png}
	\caption{\acrshort{plonk}-based \acrshort{zkdapp} Interaction Process Flow}
	\label{fig:zk-DAppgeneral}
\end{figure}
For deployment, broadcasting, and development, hardhat testnet is used. Metamask is used as a crypto wallet browser plugin.

\subsection{Artifact}
Different roles and the steps to be performed in the \acrshort{zkdapp} are described as follows.
\begin{enumerate}
\item The process flow and general functionalities are depicted.
\item Essential implementation logic and features are highlighted with references to the implementation code.
\end{enumerate}
For the \acrshort{zkdapp} to start, the command \textit{yarn start} needs to be executed in the zkdocs-backend directory. It will start the hardhat test network and show a set of test accounts with private keys to use. These test accounts are also used for the accounts of the verifier, submitter, and attesters. The following command in Figure \ref{fig:second-cmd} is also run in the same directory and deploys the schema for the \acrshort{mro} data entry. It triggers the circom and snarkjs ceremonies and shows the number of constraints, inputs, outputs, wires, and labels in the arithmetic circuit. Also, it shows that the corresponding \acrshort{r1cs}, symbols, and witness-generating files are written successfully. Once the setup is finished, the public keys of the deployer (submitter), \acrshort{plonk} verifier (PlonkVerifier.sol smart contract address), and zkDoc (ZkDocument.sol smart contract address) are shown. The zkDoc public key needs to be parsed every time another set of inputs needs to be made or verification needs to be performed. Ultimately, the schema is created, and the corresponding directories are listed. The UI can be started with the same command \textit{yarn start} in the zkdocs-ui directory.

\begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{Pictures/second-cmd.png}
	\caption{Initiating the Deployment of \acrshort{plonk} in circom, snarkjs in the \acrshort{zkdapp} Backend}
	\label{fig:second-cmd}
\end{figure}

\subsubsection{Sequence of events}
The \acrshort{zkdapp} has three roles: verifier, submitter, and attester. In this scenario, the verifier also acts as administrator, operating the \acrshort{zkdapp}. Hence, the administrator operates the schema with constraints, fields, and the list of trusted institutions that can attest in the \acrshort{zkdapp}. The submitter owns \acrshort{mro} data and seeks validation. The attester is assigned to view specific information shared with them and can validate it, i.e., attest to the data provided. The verifier can obtain the proof and verify it. Other stakeholders in the system can learn that there is verified information but do not learn anything besides its correctness. The following sequence of events refers to the landing page of the \acrshort{zkdapp} (Figure \ref{fig:landing-page}).
\begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{Pictures/landingpage.png}
	\caption{\acrshort{zkdapp} Landing Page}
	\label{fig:landing-page}
\end{figure}
\begin{enumerate}
\item \textit{Fill Form}:
The submitter connects their wallet and can see an input mask for \acrshort{mro} data entries (Figure \ref{fig:form}. In this prototype, the submitter can enter the part identifier, flight hours, time since the last service, and \acrshort{mro} cycles. Once the values are added, the submitter decides which authority needs to attest to the values, e.g., \acrshort{faa}, \acrshort{easa}. If the constraints are met, the submitter generates the proof, which results in the following: First, the proof is generated and displayed. Second, communication links are generated, which can be parsed in another browser tab. These links are specific to the respective attesters, so the data assigned to them can be viewed. In practice, this has to be realized via separate communication channels to alert attesters once a new set of \acrshort{mro} data inputs is performed. The submitter commits to these entries and the proof on-chain. Now, the values can be viewed by the respective attester and validated.

\item \textit{Attest to \acrshort{mro} data}: The respective attester follows the attestation link, connects their wallet, and only sees the decrypted values of the data assigned to them for validation. The attester marks the data as valid and commits the result. Verification can be initiated once all attesters have successfully attested to the data.

\item \textit{Verify Form}: Another user, e.g., the administrator, the submitter, or any dedicated user with the proof, can perform the verification. The verifier connects their wallet and checks the attestations. The only information available is the green mark, that data has been successfully attested to, which fields have been attested to, and who attested to these fields and values. The values are shown in an encrypted format. With the proof parsed, the verifier can verify and submit. If the attestations are correct, a bit will be flipped in the smart contract \citep{zkdocs}, and the verification will be successfully performed.

\item \textit{View Verified}: Any participant can view the latest verified information. However, only the green mark shows whether the data is correct, the field names, and which trusted authority performed the attestation. The verifier and other participants learn nothing besides that the information provided is correct and has been truthfully attested by a trusted institution.
\end{enumerate}

\begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{Pictures/form.png}
	\caption{\acrshort{zkdapp} Fill Form (Initial)}
	\label{fig:form}
\end{figure}

\subsubsection{Highlighted features}
The following features illustrate the underlying functionality applied in the \acrshort{zkdapp}.


The circuit and witness calculation input is processed through a schema. The JSON template is a rule book for the input field and values, constraints, and trusted attesting addresses. \textit{ZkDocSchema.ts} uses the JSON template to define the schema. It sets valid operators and constraint types and validates if the template matches those. Some further value validations are build-in as well, e.g., checks for non-negative numbers. 

\textit{ZkDocGenerator.ts} acts as wrapper for circom and snarkjs. It contains all necessary commands to initiate the circuit, represent intermediate formats, e.g., \acrshort{r1cs}, calculate the witness and the zero-knowledge key file, and export the verifier as smart contract. It generates the constraint string and looks up the field indices of the fields to attest in the schema. The circuit's functionality is specified in \textit{circuit.circom}. It defines the constraints checks for each field if the commitment matches the hashed commitment on-chain. During attestation, the assigned attester performs the decryption of the values locally.

The actual user input values are handled in the \textit{ZkDocument.sol} smart contract. It stores the selected attester addresses, the submitter's address, field commitments, and field indices to be attested. A nonce is generated for each field and value, and the commitment scheme is initiated. The commitment scheme for each field is hash(value, nonce). The hashing algorithm used in the circuit is POSEIDON. Due to its reduced prover and verifier complexity, POSEIDON is currently favored in research and developing zero-knowledge decentralized applications. Unlike other popular hashing functions, e.g., SHA-256, POSEIDON can operate on smaller circuits and is adapted to finite fields \citep{poseidon}. It can add and remove trusted attesters from the list via \textit{(addValidInstitution, addValidInstitutions, removeValidInstitution)}. It ensures that only the attester specified by the submitter via mask entry can attest to the fields and values committed. During this check, it is also secured that the attestation's field index matches the one specified during submission. Once the check is successful, the bit is flipped to confirm the correctness of the attestation. This procedure is simultaneously applied to all field attestations via \textit{attestMultiple}. 

The function \textit{postFields} posts the commitments and checks that 1. the commitment length matches the number of fields, 2. the correct number of institutions to perform attestations are in the commitment, and 3. the commitment is unique, and has not been posted previously. Through \textit{validateSubmitter}, the public signal array for \acrshort{plonk} verification is filled with the commitments. It checks that the specified institutions have attested to all fields. As described in the introduction of circom and snarkjs in Chapter 6.2, the verifier is transformed to a Solidity smart contract \textit{PlonkVerifier.sol}), containing the values and function logic needed for \acrshort{plonk} verification. \textit{ZkDocument.sol} uses the interface to \textit{PlonkVerifier.sol}, the \textit{IPlonkVerifier.sol} to initiate the function \textit{verifyProof}, which verifies the proof. By using the interface, it is made sure that a specific standardized function from the generated \textit{PlonkVerifier.sol} is used (\textit{verifyProof}). This way of implementation ensures that the state of \textit{PlonkVerifier.sol} undergoes an actual change. In order to prevent client-side attacks, the schema hash, using the Keccak-256 hashing algorithm (part of SHA-3 Solidity family), is stored in \textit{ZkDocument.sol} as well. 

The UI finds the correct schema via the scheme hash stored, facilitated through \textit{SchemaUtils.ts}. It obtains the corresponding schema from the schema hash and can utilize the files generated through the \acrshort{plonk} procedure in circom and snarkjs.
\begin{comment}
ÜBERLEITUNG: 
- use case support system for predictive maintenance
- \acrshort{mro} KPIs are found in different documents, have to be attested by different institutions: e.g. shop report -->repair shop, release certificate-->aviation authority
- also for trading this is important information 
- this use case resulted from requirement privacy and transparency as well as trading of parts
- assumption: data is available
- überleitung zur daten architektur: automatic verification of part id and its true existence through merkle tree zk verification
\end{comment}

\section{Evaluation}

\subsubsection{\acrshort{zkdapp} \acrshort{mro} Attestations}
On the developer's machine with a 2,2 GHz 6-Core Intel Core i7 processor and macOS 13.2.1 (22D68) operating system, the circom build, snarkjs \acrshort{plonk} setup, and contracts deployment is executed in 6.90 seconds. Although it has weaknesses compared to Groth16, the implementation with \acrshort{plonk} is motivated by its capability to be built on top of any polynomial commitment scheme. This feature makes it applicable in zk-Rollups, i.e., the compatibility with the EVM (Ethereum Virtual Machine) is responsible for the massive scaling of the Ethereum blockchain. Additionally, there is the outlook for the future availability of the snarkjs TURBOPLONK, whereby the number of gates is decreased by introducing custom gates appearing multiple times within a circuit. Comparisons with implementations based on the MiMC hash show that \acrshort{plonk} outperforms Groth16 2.5 times \citep{turboplonk}. While the performance depends on the underlying curves and their field sizes, resulting in different pairing friendliness, recent comparisons with Poseidon-128 show less prover time with \acrshort{plonk}. \acrshort{plonk} operates with a larger proof size, i.e., 9 elements in \begin{math} \mathbb{G}\end{math} and additional 7 field elements in \begin{math} \mathbb{F}\end{math} \citep{PLONKcryptoeprint:2019/953}. In comparison, Groth16 only needs 2 elements in \begin{math} \mathbb{G}_1\end{math} and 2 elements in \begin{math} \mathbb{G}_2\end{math}. Any smart contract modification, e.g., circuit change, needs a new trusted setup. For the Aztec protocol, the private transaction protocol for the Ethereum mainnet, this procedure took more than six weeks \citep{turboplonk}. All \acrshort{zksnark} implementations need a trusted setup, which can be made less centralized via \acrshort{mpc}. An \acrshort{mpc} is characterized by many different parties initializing the generation of proving and the verifying key for the trusted setup \citep{Thaler}. 

The result of the evaluation cycle is described as follows, taking feedback from the recent project workshop into consideration: The implementation of the software artifact \acrshort{zkdapp} represents a seized opportunity to meet the second project requirement of constructing a trade-off between privacy, confidentiality, and transparency. This requirement is successfully met due to the nature of zero-knowledge proofs realizing transparency and confidentiality in a trustless environment of \acrshort{mro} spare parts validation. 

On the one hand, the use case of \acrshort{mro} key performance indicator (\acrshort{kpi}) validation needs to be revisited and could be replaced to meet more urgent project targets, e.g., validation of non-\acrshort{kpi} relevant \acrshort{mro} data. The data in the prototype is captured per part identifier only, i.e., the form identifier is obsolete for this prototype. The time since the last service on the part was performed is also relevant and should be added as a third constraint (Figure \ref{fig:form}). The data points are to be perceived as stand-alone, i.e., validation calculation checks and threshold values yet have to be investigated. Except for the data points, further content analysis and feedback in the \acrshort{mro} industry will be performed in future research to match the use case in this prototype in more granularity.

On the other hand, the demonstration of the technical functionality is successful, and the previously developed \acrshort{dapp} for \acrshort{mro} certificate validation and the \acrshort{mro} Smart Hub (in development through Opremic GmbH) can be extended with the zero-knowledge proof functionality of this software artifact. The current code shared with the thesis shows the implementation of the most recent feedback of the evaluation cycle. A screenshot of the input screen (in analogy to Figure \ref{fig:form}) is shown below (Figure \ref{fig:form1}).
\begin{figure}[hbt]
	\centering
		\includegraphics[width=0.8\textwidth]{Pictures/bsp2.png}
	\caption{\acrshort{zkdapp} Fill Form (Follow-Up after Evaluation)}
	\label{fig:form1}
\end{figure}
Assumptions about the data structure led to the development of the first \acrshort{zkdapp} prototype and are revisited during the evaluation cycle to review the application's data layer in more detail. Current paper-based documentation must be replaced by the automatic digitization of spare part certificates and brought into a practical storage structure with part identifiers and corresponding certificate identifiers. While the automatic digitization of spare part documents is being realized in the project via optical character recognition (OCR), the authenticity validation check of these data in a trustless environment is still to be approached. As an evaluation aspect for further research implementation, an architectural zero-knowledge data structure is outlined as an opportunity to meet the third project requirement. In parallel, this architecture is the basis to increasingly capture \acrshort{mro} \acrshort{kpi} data through combination with the \acrshort{zkdapp} in further research. 

\subsubsection{Zero-Knowledge Data Structure}
The lack of a structured data foundation for proofing the authenticity of aviation spare part documentation is an obstacle to enabling an industry-wide adoption of a blockchain-based industry standard for document verification approaches. In combination with the document issuing organization, there is a need to prove the authenticity of documents, e.g., via a transparent availability of the mechanic's signature and the document date stamp. However, this need for transparency conflicts with data privacy and the large amount of paper-based data captured in the past, which cannot be traced back effectively. Exploring a Merkle-tree-based, zero-knowledge proof data structure satisfies the third requirement to ensure document authenticity and data integrity. Further maturation of this architecture, especially the degree of integration with the \acrshort{zkdapp} prototype, must be addressed further.

Incoming \acrshort{mro} data is structured via a Merkle tree, which is initialized by an aggregator role, the operator. The operator receives data sent by the client, e.g., a \acrshort{zkdapp}. The operator maintains the Merkle tree locally. Once \acrshort{mro} data is submitted, newly created leaves are added to the Merkle tree. The structure is organized as follows: spare parts and subordinated certificates have a unique identifier, e.g., a part identifier has many certificates, each with a unique part id and certificate id combination. Each certificate is issued by an organization that employs mechanics. Mechanics service spare parts, generate \acrshort{mro} data and sign the certificate. The leaves contain the mechanics signature, the \acrshort{mro} data, e.g., the same values collected via the \acrshort{zkdapp} prototype, and a time stamp—the Merkle root results from a specific state of the spare part documentation history. The Merkle tree represents the local running account for \acrshort{mro} data capturing and is entirely maintained off-chain. 

The architecture (Figure \ref{fig:arch}) ensures local and global data integrity. The operator is responsible for proving local data integrity. Through Merkle proofs and blockchain receipts, users can track whether their submitted data was correctly included in the structure. The operator keeps its local Merkle tree with sensitive \acrshort{mro} data off-chain but maintains the Merkle root via blockchain. Users must trust the operator with their data privacy during transfer, but not with the integrity of maintaining correct account keeping \citep{sedlemeirgrenenergy}. 

\begin{figure}[hbt]
	\centering
		\includegraphics[width=1.0\textwidth]{Pictures/architecture.png}
	\caption{Zero-Knowledge Data Structure Architecture}
	\label{fig:arch}
\end{figure}
Data integrity is not achieved through trust due to this architecture's introduction of zero-knowledge proofs. In order to decentralize the accounting for correct \acrshort{mro} data submission and to prevent fraud on the side of the operator, the use of Merkle proofs alone is not yet sufficient. It needs to be ensured that the generation of \acrshort{mro} data matches globally in the Merkle tree structure. In order to prove the authenticity of any newly batched update, the operator sends the suggestion for the new Merkle root to a smart contract as zero-knowledge proof during periodical Merkle tree updates. As it is known with \acrshort{zksnark}s, all parties must agree on a proving and a verifying key via \acrshort{mpc}, i.e., the trusted setup is initialized. Public inputs are previously correct Merkle root updates. The witness is the signed input submitted by the users and the entire Merkle tree. With this at hand, the operator can generate a zero-knowledge proof to be sent to the smart contract. The smart contract can then verify this proof through the verifying key and the previous Merkle root. Once the proof is considered valid through most nodes participating, the Merkle root can be updated in the smart contract, creating global integrity and transparency for third-party audits. 

This proposal for a zero-knowledge data structure provides the scope to securely manage the documentation of spare parts and certificate data and prove their authenticity by incorporating a zk-rollup-based architecture.


\begin{comment}
- USE CASE: check the authenticity of MRO spare part documentation-->currently hard to achieve due to paper based documentation
- big need to prove authenticity, e.g., through checking if mechanic and date stempel match with a part if and certificate id
- big need to strive towards a decentralized temper-proof data structure
-create a architecture for verification mechanisms in Rapado, based on Sedlmeier, Völter, Strüker (2021):
-->proof membership in a merkle tree? data structure of parts, certificates

- Campanelli et al 2022: improvement on zkSNARKS with Merkle Trees -->HARISA, could be used for the architecture

- build zk DAPP for document verification with circom snarkjs on hardhat test network
- maybe use snarkjs Groth16 first and then Plonk as future outlook, when TurboPlonk support will come in snarkjs

-do one evaluation cycle: which design requirements are met?

feedback from Opremic: 
- MRO data tracked per part Id
- add time since last service as entry, remove form id
- add third constraint
- constraints are stand-alone, no equations yet identified
-add generic attester: Validation Network
- more systematic user interviews needed for this use case, but technical functionality is easily displayed via this use case

- why is the architecture good -->because it tackles the assumptions that are made for the \acrshort{zkdapp} and focuses on another big requirement in the project: the data digitization approach
- comparison of groth16 and Plonk performance
- limitations of the implementation
- future outlook with turboplonk

content:
- data has to be made more available: automatic part id verification, automatic assignment of attesters according to fields (e.g. MRO cycles always done by repair shop)
- also automatic threshold identification according to part id and part description: e.g. a turbine needs another threshold than a wing
- data structure will dictate industry effectiveness of zero-knowledge proof implementations in the project as well as adoption
- \acrshort{zkdapp} flexible and easy to adapt to further business cases
- the data structure verification with zero-knowledge proposes another way of making use of ZKP for the requirement to create a industry standard for MRO data digitization and verification


---------------RAPADO Workshop May 8
- certificates must be checked for authenticity first
- then data structure is needed to store part id+serial number+ form number and name of mechanic
- Daten des Mechanikers liegen aber in seiner Organisation, das ist Hauptproblem
- Datenschutz
-current: Stammdatensatz, aus dem statistische evaluierung erfolgen soll
- diese datenstruktu könnte als support system dienen für die validierer, validierung kann bis zu 3 wochen dauern




-am ende unbedingt auf manuellen aufwand eingehen+shortage of validation staff, und die verschwendung weil zweitmarkt fehlt 
- kosten sind am höchsten bei der überfühurng in blockchain-->zkps weg zur kostensenkung



\end{comment}


